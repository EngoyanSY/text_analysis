{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>А-02-21 Енгоян Сергей ЛР 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.windows.x', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=28, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=28, categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем по одному тексту каждой их 3 категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.windows.x \n",
      "I think the original post was searching for existing implementations of\n",
      "f.i. Gouroud-shading of triangles. This is fairly complex to do with plain\n",
      "X. Simpler shading models are implemented already, f.i. in x3d (ask archie\n",
      "where to get the latest version).\n",
      "For Gouroud, a fast implementation will be possible utilizing some extension\n",
      "only, either MIT-SHM to do the shade in an image and fast update the window\n",
      "with it, or PEX/OpenGL which should be able to shade themselves. The portable\n",
      "'vanilla X' way would be to shade in a normal XImage and use XPutImage(),\n",
      "what would be good enough to do static things as f.i. fractal landscapes\n",
      "or such stuff.\n",
      "\n",
      "To speak about POVRay, the X previewer that comes with the original source\n",
      "package is not that good, especially in speed, protocol-friendlyness and\n",
      "ICCCM compliance. Have a look on x256q, my own preview code. It is on\n",
      "\n",
      "141.76.1.11:pub/gfx/ray/misc/x256q/\n",
      "\n",
      "The README states the points where it is better than xwindow.c from\n",
      "POVRay 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[5]], twenty_train.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey \n",
      "\n",
      "\n",
      "Well, it seems that the Habs have been much talked-about of late, so here's my\n",
      "$0.02.  These guys have absolutely no concept of how to play in front of the\n",
      "damn net!!!  Watch them in the offensive zone, especially on the powerplay. \n",
      "Damphousse or Lebeau will skate all over the bloody zone, maybe pass to the\n",
      "point, get it back, skate some more, pass it around....BUT WHERE'S THE SHOT??!\n",
      "Answer: the shot is totally useless because they lack a forward who stands\n",
      "in front of the net a la` Neely, Shanahan, Tocchet, etc etc.  Too bad \n",
      "Demers won't put Dipietro or LeClair on the powerplay more often.  Dammit,\n",
      "even Ewen would at least cause some disruptions.  Montreal desperately needs\n",
      "a power forward with some talent, IMO.\n",
      "\n",
      "Then watch them in their own zone. Patrick Roy is screened on everything. Say\n",
      "what you want about his performance; IMNSHO he cannot stop what he cannot see. \n",
      "And Montreal's defence does a miserable job of clearing the front of the net. \n",
      "Last night against Washington Roy played a *great* game.  The first goal came\n",
      "on the most ridiculous goalmouth scramble I've seen in a long time, and he\n",
      "didn't have a hope in hell of stopping the shot.  The second goal came on a\n",
      "deflection of a shot he only partially saw anyway.  Pathetic defence.  The\n",
      "third goal was EN.\n",
      "\n",
      "No wonder he gets pissed off at his defencemen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[1]], twenty_train.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.baseball Amazingly, pitchers, no matter how good their mechanics, are\n",
      "not machines.  Cy Young winners don't pitch in a vaccuum, unaware\n",
      "of how their offenses are doing.\n",
      "\n",
      "\tThe Braves' pitching staff is already showing signs of\n",
      "cracking under the strain of knowing they're not going to get many\n",
      "(if any) runs.  Unfortunately, the Braves' pitchers were so bad for so\n",
      "long that the organization put so much stress (and I mean *stress*)\n",
      "on pitching that they completely ignored hitting.\n",
      "\n",
      "\tThe Braves right now are looking woefully similar to the Braves of\n",
      "the mid-seventies.  Heaven help us.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[13]], twenty_train.data[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>Стемминг</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "stem_train = []\n",
    "stem_test = []\n",
    "for text in twenty_train.data:\n",
    "    nltk_tokens = word_tokenize(text)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    stem_train.append(line)\n",
    "\n",
    "for text in twenty_test.data:\n",
    "    nltk_tokens = word_tokenize(text)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    stem_test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, it seems that everyone else in canada was treated to the \n",
      "REAL ABC telecast while only the people on ROGERS TV in Surrey BC \n",
      "were treated to two channels with Don \"I stink as a Commentator\" Whitman\n",
      "doing the play-by-play.\n",
      " ok , it seem that everyon els in canada wa treat to the real abc telecast while onli the peopl on roger tv in surrey bc were treat to two channel with don `` i stink as a comment '' whitman do the play-by-play .\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])\n",
    "print(stem_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>Векторизация</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_1 = CountVectorizer(max_features=10000)\n",
    "\n",
    "train_data = vect_1.fit_transform(twenty_train.data)\n",
    "test_data = vect_1.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', np.int64(15749))\n",
      "('to', np.int64(7012))\n",
      "('and', np.int64(5437))\n",
      "('of', np.int64(5008))\n",
      "('in', np.int64(4583))\n",
      "('is', np.int64(3967))\n",
      "('that', np.int64(3001))\n",
      "('for', np.int64(2833))\n",
      "('it', np.int64(2597))\n",
      "('on', np.int64(2307))\n",
      "('you', np.int64(2059))\n",
      "('this', np.int64(2006))\n",
      "('be', np.int64(1979))\n",
      "('with', np.int64(1708))\n",
      "('have', np.int64(1652))\n",
      "('are', np.int64(1634))\n",
      "('he', np.int64(1524))\n",
      "('if', np.int64(1522))\n",
      "('as', np.int64(1453))\n",
      "('but', np.int64(1438))\n"
     ]
    }
   ],
   "source": [
    "x_1 = list(zip(vect_1.get_feature_names_out(), np.ravel(train_data.sum(axis=0))))\n",
    "def SortbyTF(inputStr):\n",
    "    return inputStr[1]\n",
    "x_1.sort(key=SortbyTF, reverse = True)\n",
    "\n",
    "for _ in x_1[:20]:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Частые термины для категории: comp.windows.x\n",
      "the: 6750\n",
      "to: 3486\n",
      "and: 2447\n",
      "of: 2296\n",
      "is: 2269\n",
      "in: 1848\n",
      "for: 1394\n",
      "it: 1261\n",
      "on: 1141\n",
      "that: 1130\n",
      "this: 1125\n",
      "you: 1066\n",
      "be: 956\n",
      "are: 893\n",
      "if: 836\n",
      "with: 821\n",
      "or: 778\n",
      "can: 756\n",
      "an: 730\n",
      "not: 699\n",
      "\n",
      "Частые термины для категории: rec.sport.baseball\n",
      "the: 3508\n",
      "to: 1481\n",
      "and: 1312\n",
      "of: 1142\n",
      "in: 1114\n",
      "that: 882\n",
      "is: 842\n",
      "he: 738\n",
      "for: 580\n",
      "it: 543\n",
      "have: 494\n",
      "was: 466\n",
      "but: 451\n",
      "be: 448\n",
      "you: 443\n",
      "on: 441\n",
      "this: 416\n",
      "they: 409\n",
      "at: 404\n",
      "with: 393\n",
      "\n",
      "Частые термины для категории: rec.sport.hockey\n",
      "the: 5491\n",
      "to: 2045\n",
      "and: 1678\n",
      "in: 1621\n",
      "of: 1570\n",
      "that: 989\n",
      "for: 859\n",
      "is: 856\n",
      "it: 793\n",
      "he: 776\n",
      "was: 731\n",
      "on: 725\n",
      "be: 575\n",
      "you: 550\n",
      "at: 547\n",
      "but: 532\n",
      "have: 512\n",
      "with: 494\n",
      "team: 478\n",
      "as: 466\n"
     ]
    }
   ],
   "source": [
    "category_names = twenty_train.target_names\n",
    "category_indices = twenty_train.target\n",
    "\n",
    "word_freq_pairs_1 = {}\n",
    "\n",
    "for cat_idx, cat_name in enumerate(twenty_train.target_names):\n",
    "    print(f\"\\nЧастые термины для категории: {cat_name}\")\n",
    "\n",
    "    cat_mask = (category_indices == cat_idx)\n",
    "    cat_data = train_data[cat_mask]\n",
    "    \n",
    "    word_frequencies = np.ravel(cat_data.sum(axis=0))\n",
    "    word_freq_pairs_1[cat_idx] = list(zip(vect_1.get_feature_names_out(), word_frequencies))\n",
    "    word_freq_pairs_1[cat_idx].sort(key=SortbyTF, reverse=True)\n",
    "\n",
    "    for word, freq in word_freq_pairs_1[cat_idx][:20]:\n",
    "        print(f\"{word}: {freq}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсечение стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('team', np.int64(679))\n",
      "('game', np.int64(633))\n",
      "('year', np.int64(629))\n",
      "('file', np.int64(586))\n",
      "('like', np.int64(582))\n",
      "('10', np.int64(580))\n",
      "('window', np.int64(573))\n",
      "('edu', np.int64(544))\n",
      "('use', np.int64(512))\n",
      "('don', np.int64(502))\n",
      "('just', np.int64(480))\n",
      "('time', np.int64(466))\n",
      "('new', np.int64(437))\n",
      "('good', np.int64(434))\n",
      "('think', np.int64(429))\n",
      "('play', np.int64(427))\n",
      "('season', np.int64(424))\n",
      "('program', np.int64(417))\n",
      "('games', np.int64(416))\n",
      "('11', np.int64(415))\n",
      "\n",
      "Частые термины для категории: comp.windows.x\n",
      "file: 579\n",
      "window: 571\n",
      "use: 459\n",
      "program: 412\n",
      "server: 385\n",
      "edu: 377\n",
      "motif: 356\n",
      "widget: 354\n",
      "entry: 351\n",
      "output: 315\n",
      "available: 306\n",
      "com: 274\n",
      "set: 274\n",
      "using: 269\n",
      "mit: 254\n",
      "application: 253\n",
      "like: 247\n",
      "information: 245\n",
      "sun: 240\n",
      "does: 232\n",
      "\n",
      "Частые термины для категории: rec.sport.baseball\n",
      "year: 310\n",
      "game: 204\n",
      "good: 200\n",
      "team: 195\n",
      "think: 189\n",
      "don: 186\n",
      "00: 175\n",
      "just: 161\n",
      "like: 153\n",
      "games: 149\n",
      "better: 140\n",
      "baseball: 137\n",
      "hit: 137\n",
      "runs: 137\n",
      "players: 135\n",
      "time: 131\n",
      "02: 125\n",
      "won: 124\n",
      "league: 118\n",
      "03: 116\n",
      "\n",
      "Частые термины для категории: rec.sport.hockey\n",
      "team: 478\n",
      "game: 423\n",
      "10: 406\n",
      "hockey: 365\n",
      "25: 352\n",
      "play: 343\n",
      "55: 340\n",
      "season: 312\n",
      "11: 311\n",
      "12: 282\n",
      "16: 273\n",
      "games: 265\n",
      "period: 257\n",
      "14: 256\n",
      "15: 252\n",
      "18: 247\n",
      "20: 242\n",
      "nhl: 236\n",
      "13: 233\n",
      "year: 228\n"
     ]
    }
   ],
   "source": [
    "vect_2 = CountVectorizer(max_features=10000, stop_words='english')\n",
    "\n",
    "train_data = vect_2.fit_transform(twenty_train.data)\n",
    "test_data = vect_2.transform(twenty_test.data)\n",
    "\n",
    "x_2 = list(zip(vect_2.get_feature_names_out(), np.ravel(train_data.sum(axis=0))))\n",
    "def SortbyTF(inputStr):\n",
    "    return inputStr[1]\n",
    "x_2.sort(key=SortbyTF, reverse = True)\n",
    "\n",
    "for _ in x_2[:20]:\n",
    "    print(_)\n",
    "\n",
    "category_names = twenty_train.target_names\n",
    "category_indices = twenty_train.target\n",
    "\n",
    "word_freq_pairs_2 = {}\n",
    "\n",
    "for cat_idx, cat_name in enumerate(twenty_train.target_names):\n",
    "    print(f\"\\nЧастые термины для категории: {cat_name}\")\n",
    "\n",
    "    cat_mask = (category_indices == cat_idx)\n",
    "    cat_data = train_data[cat_mask]\n",
    "    \n",
    "    word_frequencies = np.ravel(cat_data.sum(axis=0))\n",
    "    word_freq_pairs_2[cat_idx] = list(zip(vect_2.get_feature_names_out(), word_frequencies))\n",
    "    word_freq_pairs_2[cat_idx].sort(key=SortbyTF, reverse=True)\n",
    "\n",
    "    for word, freq in word_freq_pairs_2[cat_idx][:20]:\n",
    "        print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт А для выборки со стеммингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thi', np.int64(2006))\n",
      "('wa', np.int64(1456))\n",
      "('use', np.int64(1130))\n",
      "('game', np.int64(1037))\n",
      "('team', np.int64(912))\n",
      "('ha', np.int64(852))\n",
      "('year', np.int64(817))\n",
      "('file', np.int64(777))\n",
      "('hi', np.int64(735))\n",
      "('play', np.int64(732))\n",
      "('window', np.int64(724))\n",
      "('like', np.int64(657))\n",
      "('ani', np.int64(621))\n",
      "('run', np.int64(615))\n",
      "('program', np.int64(600))\n",
      "('10', np.int64(580))\n",
      "('doe', np.int64(568))\n",
      "('player', np.int64(549))\n",
      "('edu', np.int64(544))\n",
      "('time', np.int64(523))\n",
      "\n",
      "Частые термины для категории: comp.windows.x\n",
      "thi: 1125\n",
      "use: 988\n",
      "file: 763\n",
      "window: 721\n",
      "program: 591\n",
      "entri: 471\n",
      "widget: 469\n",
      "server: 418\n",
      "edu: 377\n",
      "ani: 367\n",
      "motif: 357\n",
      "run: 351\n",
      "includ: 346\n",
      "set: 346\n",
      "applic: 334\n",
      "doe: 318\n",
      "output: 316\n",
      "avail: 313\n",
      "ha: 301\n",
      "work: 297\n",
      "\n",
      "Частые термины для категории: rec.sport.baseball\n",
      "wa: 493\n",
      "thi: 416\n",
      "year: 405\n",
      "game: 349\n",
      "hi: 337\n",
      "team: 270\n",
      "ha: 260\n",
      "run: 237\n",
      "player: 216\n",
      "think: 208\n",
      "hit: 205\n",
      "good: 200\n",
      "pitch: 187\n",
      "like: 183\n",
      "00: 175\n",
      "win: 171\n",
      "play: 163\n",
      "just: 161\n",
      "did: 154\n",
      "doe: 146\n",
      "\n",
      "Частые термины для категории: rec.sport.hockey\n",
      "wa: 765\n",
      "game: 680\n",
      "team: 635\n",
      "play: 564\n",
      "thi: 465\n",
      "10: 406\n",
      "hockey: 367\n",
      "25: 352\n",
      "55: 340\n",
      "player: 333\n",
      "season: 325\n",
      "hi: 321\n",
      "11: 311\n",
      "year: 311\n",
      "pt: 307\n",
      "ha: 291\n",
      "12: 282\n",
      "16: 273\n",
      "period: 264\n",
      "14: 256\n"
     ]
    }
   ],
   "source": [
    "vect_3 = CountVectorizer(max_features=10000, stop_words='english')\n",
    "\n",
    "train_data = vect_3.fit_transform(stem_train)\n",
    "test_data = vect_3.transform(stem_test)\n",
    "\n",
    "x_3 = list(zip(vect_3.get_feature_names_out(), np.ravel(train_data.sum(axis=0))))\n",
    "def SortbyTF(inputStr):\n",
    "    return inputStr[1]\n",
    "x_3.sort(key=SortbyTF, reverse = True)\n",
    "\n",
    "for _ in x_3[:20]:\n",
    "    print(_)\n",
    "\n",
    "category_names = twenty_train.target_names\n",
    "category_indices = twenty_train.target\n",
    "\n",
    "word_freq_pairs_3 = {}\n",
    "\n",
    "for cat_idx, cat_name in enumerate(twenty_train.target_names):\n",
    "    print(f\"\\nЧастые термины для категории: {cat_name}\")\n",
    "\n",
    "    cat_mask = (category_indices == cat_idx)\n",
    "    cat_data = train_data[cat_mask]\n",
    "    \n",
    "    word_frequencies = np.ravel(cat_data.sum(axis=0))\n",
    "    word_freq_pairs_3[cat_idx] = list(zip(vect_3.get_feature_names_out(), word_frequencies))\n",
    "    word_freq_pairs_3[cat_idx].sort(key=SortbyTF, reverse=True)\n",
    "\n",
    "    for word, freq in word_freq_pairs_3[cat_idx][:20]:\n",
    "        print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жаккар между comp.windows.x и rec.sport.baseball: 0.1073583965450418\n",
      "Жаккар между comp.windows.x и rec.sport.hockey: 0.05842506350550381\n",
      "Жаккар между rec.sport.baseball и rec.sport.hockey: 0.17674746999293953\n",
      "Отсечение стоп-слов\n",
      "Жаккар между comp.windows.x и rec.sport.baseball: 0.11117284293571865\n",
      "Жаккар между comp.windows.x и rec.sport.hockey: 0.05803311643654446\n",
      "Жаккар между rec.sport.baseball и rec.sport.hockey: 0.1904053330158919\n",
      "Стемминг и стоп-слова\n",
      "Жаккар между comp.windows.x и rec.sport.baseball: 0.1385631333257429\n",
      "Жаккар между comp.windows.x и rec.sport.hockey: 0.06241699867197875\n",
      "Жаккар между rec.sport.baseball и rec.sport.hockey: 0.19431506031291054\n"
     ]
    }
   ],
   "source": [
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[1]}:\", jaccard_similarity(word_freq_pairs_1[0], word_freq_pairs_1[1]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_1[0], word_freq_pairs_1[2]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[1]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_1[1], word_freq_pairs_1[2]))\n",
    "print('Отсечение стоп-слов')\n",
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[1]}:\", jaccard_similarity(word_freq_pairs_2[0], word_freq_pairs_2[1]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_2[0], word_freq_pairs_2[2]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[1]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_2[1], word_freq_pairs_2[2]))\n",
    "print('Стемминг и стоп-слова')\n",
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[1]}:\", jaccard_similarity(word_freq_pairs_3[0], word_freq_pairs_3[1]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[0]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_3[0], word_freq_pairs_3[2]))\n",
    "print(f\"Жаккар между {twenty_train.target_names[1]} и {twenty_train.target_names[2]}:\", jaccard_similarity(word_freq_pairs_3[1], word_freq_pairs_3[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
